{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mnist分类任务：\n",
    "\n",
    "- 网络基本构建与训练方法，常用函数解析\n",
    "\n",
    "- torch.nn.functional模块\n",
    "\n",
    "- nn.Module模块\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取Mnist数据集\n",
    "- 会自动进行下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "784是mnist数据集每个样本的像素点个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "#cmap=\"gray\" 灰度图\n",
    "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/4.png\" alt=\"FAO\" width=\"790\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/5.png\" alt=\"FAO\" width=\"790\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意数据需转换成tensor才能参与后续建模训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "# n 是样本的个数，c 是像素点的个数\n",
    "n, c = x_train.shape\n",
    "x_train, x_train.shape, y_train.min(), y_train.max()\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.nn.functional 很多层和函数在这里都会见到\n",
    "\n",
    "torch.nn.functional中有很多功能，后续会常用的。那什么时候使用nn.Module，什么时候使用nn.functional呢？一般情况下，如果模型有可学习的参数，最好用nn.Module，其他情况nn.functional相对更简单一些\n",
    " * torch.nn.functional是封装好的，但是灵活性不佳，nn.Module是实际开发中更常用的，便于自定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb.mm(weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.7272, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bs = 64 # batch_size 样本的个数\n",
    "xb = x_train[0:bs]  # a mini-batch from x\n",
    "yb = y_train[0:bs]\n",
    "weights = torch.randn([784, 10], dtype = torch.float,  requires_grad = True) \n",
    "bs = 64\n",
    "bias = torch.zeros(10, requires_grad=True)\n",
    "# 损失函数 需要输入两个值 第一个是预测值，第二个是标签\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建一个model来更简化代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 必须继承nn.Module且在其构造函数中需调用nn.Module的构造函数\n",
    "- 无需写反向传播函数，nn.Module能够利用autograd自动实现反向传播\n",
    "- Module中的可学习参数可以通过named_parameters()或者parameters()返回迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nn模块就是神经网络了\n",
    "from torch import nn\n",
    "\n",
    "class Mnist_NN(nn.Module):\n",
    "    # 构造函数\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 这里已经nn.Linear方法已经定义好了权重参数\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "        self.hidden2 = nn.Linear(128, 256)\n",
    "        self.out  = nn.Linear(256, 10)\n",
    "        # dropout 防止过拟合，0.5表示杀死50%的神经元\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    # 前向传播，Torch中分为前向传播和反向传播，前向传播就是传进参数然后计算预测值的过程，反向传播主要是优化，Torch自带，一行代码就可以编写\n",
    "    # 这里的 x 参数是 64 * 784 \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        # 在全链接过程中必须加入dropout，但是卷积可以不用\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist_NN(\n",
      "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (hidden2): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Mnist_NN()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以打印我们定义好名字里的权重和偏置项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1.weight Parameter containing:\n",
      "tensor([[ 0.0069,  0.0163,  0.0160,  ..., -0.0275,  0.0275, -0.0098],\n",
      "        [ 0.0352, -0.0145,  0.0092,  ..., -0.0169,  0.0349, -0.0115],\n",
      "        [ 0.0086, -0.0113,  0.0110,  ...,  0.0344,  0.0216,  0.0088],\n",
      "        ...,\n",
      "        [ 0.0262, -0.0171, -0.0053,  ...,  0.0158,  0.0136,  0.0230],\n",
      "        [-0.0034, -0.0026,  0.0197,  ..., -0.0092,  0.0260,  0.0180],\n",
      "        [ 0.0049, -0.0009, -0.0034,  ...,  0.0140,  0.0025,  0.0043]],\n",
      "       requires_grad=True) torch.Size([128, 784])\n",
      "hidden1.bias Parameter containing:\n",
      "tensor([-0.0238,  0.0190, -0.0045, -0.0158, -0.0286,  0.0009, -0.0069, -0.0174,\n",
      "        -0.0184, -0.0078,  0.0268,  0.0184,  0.0303,  0.0310,  0.0296, -0.0212,\n",
      "        -0.0317,  0.0281,  0.0294, -0.0346,  0.0311, -0.0025,  0.0326,  0.0306,\n",
      "        -0.0006, -0.0242,  0.0313, -0.0231, -0.0230,  0.0294, -0.0337,  0.0286,\n",
      "         0.0330,  0.0211, -0.0337,  0.0313,  0.0212,  0.0172,  0.0092,  0.0351,\n",
      "         0.0062, -0.0038, -0.0179,  0.0179, -0.0146,  0.0217, -0.0228,  0.0030,\n",
      "        -0.0070, -0.0299, -0.0303,  0.0256,  0.0011, -0.0175,  0.0319, -0.0044,\n",
      "         0.0098, -0.0272,  0.0018, -0.0286,  0.0141, -0.0121, -0.0324, -0.0266,\n",
      "         0.0014, -0.0056, -0.0118,  0.0318,  0.0190,  0.0182, -0.0275,  0.0088,\n",
      "         0.0266,  0.0140, -0.0277,  0.0108, -0.0056,  0.0166, -0.0217, -0.0208,\n",
      "        -0.0257,  0.0312, -0.0134, -0.0307,  0.0321,  0.0154, -0.0191, -0.0311,\n",
      "        -0.0084, -0.0266,  0.0285, -0.0137, -0.0257,  0.0069, -0.0192, -0.0346,\n",
      "         0.0293, -0.0002, -0.0304,  0.0056, -0.0288,  0.0341, -0.0198, -0.0103,\n",
      "        -0.0175,  0.0195, -0.0089, -0.0330, -0.0117,  0.0321,  0.0179,  0.0275,\n",
      "        -0.0087,  0.0140,  0.0073,  0.0246,  0.0117,  0.0271,  0.0076, -0.0246,\n",
      "         0.0202, -0.0125,  0.0143, -0.0280, -0.0192,  0.0281,  0.0034,  0.0247],\n",
      "       requires_grad=True) torch.Size([128])\n",
      "hidden2.weight Parameter containing:\n",
      "tensor([[-0.0359, -0.0739, -0.0037,  ...,  0.0581, -0.0396,  0.0044],\n",
      "        [ 0.0455,  0.0802,  0.0764,  ..., -0.0276,  0.0865,  0.0824],\n",
      "        [-0.0051, -0.0621,  0.0441,  ...,  0.0838, -0.0222,  0.0318],\n",
      "        ...,\n",
      "        [-0.0209, -0.0588,  0.0276,  ..., -0.0028,  0.0009, -0.0626],\n",
      "        [ 0.0399,  0.0562,  0.0402,  ..., -0.0003, -0.0556,  0.0109],\n",
      "        [-0.0062,  0.0198, -0.0413,  ...,  0.0182, -0.0729,  0.0235]],\n",
      "       requires_grad=True) torch.Size([256, 128])\n",
      "hidden2.bias Parameter containing:\n",
      "tensor([-0.0647,  0.0162, -0.0194, -0.0302,  0.0030, -0.0442,  0.0842,  0.0079,\n",
      "        -0.0026,  0.0544,  0.0285, -0.0412, -0.0089,  0.0646, -0.0256, -0.0850,\n",
      "        -0.0750,  0.0082, -0.0311, -0.0599,  0.0162,  0.0810, -0.0685,  0.0261,\n",
      "         0.0732,  0.0383, -0.0088,  0.0246, -0.0188, -0.0616,  0.0089,  0.0796,\n",
      "        -0.0175, -0.0602,  0.0390,  0.0546,  0.0613, -0.0243, -0.0142, -0.0323,\n",
      "         0.0042,  0.0430, -0.0514, -0.0339,  0.0061,  0.0283,  0.0105,  0.0399,\n",
      "        -0.0047, -0.0607, -0.0501, -0.0360, -0.0740,  0.0217,  0.0434, -0.0565,\n",
      "        -0.0814, -0.0215, -0.0358, -0.0327,  0.0316,  0.0649, -0.0739, -0.0432,\n",
      "        -0.0134,  0.0524, -0.0815, -0.0438,  0.0447,  0.0380,  0.0557,  0.0255,\n",
      "         0.0196,  0.0388,  0.0284, -0.0525, -0.0640, -0.0514,  0.0012, -0.0236,\n",
      "         0.0026, -0.0340, -0.0855,  0.0513,  0.0789, -0.0377, -0.0760,  0.0800,\n",
      "        -0.0696, -0.0586,  0.0565, -0.0563, -0.0147,  0.0757, -0.0278, -0.0418,\n",
      "        -0.0648, -0.0203,  0.0748, -0.0595, -0.0799, -0.0355,  0.0140, -0.0448,\n",
      "        -0.0746, -0.0126, -0.0035, -0.0663,  0.0116, -0.0352, -0.0455,  0.0358,\n",
      "        -0.0193,  0.0775, -0.0151,  0.0326, -0.0296, -0.0162, -0.0550,  0.0655,\n",
      "         0.0544, -0.0571,  0.0556,  0.0507, -0.0040, -0.0778,  0.0811,  0.0102,\n",
      "        -0.0015,  0.0830,  0.0050, -0.0704,  0.0254, -0.0796, -0.0730,  0.0317,\n",
      "         0.0713,  0.0734, -0.0615, -0.0405, -0.0665,  0.0501,  0.0072, -0.0869,\n",
      "        -0.0488,  0.0053, -0.0054, -0.0780,  0.0877,  0.0317,  0.0263, -0.0324,\n",
      "        -0.0278,  0.0882,  0.0713, -0.0008, -0.0337,  0.0514,  0.0596,  0.0447,\n",
      "        -0.0017,  0.0807, -0.0185, -0.0393,  0.0848, -0.0636, -0.0267,  0.0711,\n",
      "         0.0499,  0.0070, -0.0743,  0.0697, -0.0067, -0.0062, -0.0250,  0.0400,\n",
      "        -0.0817, -0.0627,  0.0351, -0.0614, -0.0241, -0.0064,  0.0861,  0.0733,\n",
      "         0.0610, -0.0379,  0.0371,  0.0025, -0.0010,  0.0784,  0.0379, -0.0144,\n",
      "        -0.0448, -0.0371, -0.0609, -0.0554,  0.0655, -0.0539,  0.0577, -0.0231,\n",
      "        -0.0876,  0.0870, -0.0203, -0.0379, -0.0813, -0.0338, -0.0155,  0.0696,\n",
      "         0.0047, -0.0678,  0.0237,  0.0713, -0.0461,  0.0877, -0.0129,  0.0533,\n",
      "        -0.0525, -0.0043,  0.0044, -0.0285,  0.0711,  0.0431,  0.0375,  0.0359,\n",
      "         0.0085, -0.0176,  0.0249, -0.0117,  0.0680, -0.0703, -0.0441, -0.0621,\n",
      "         0.0762,  0.0283, -0.0750,  0.0679, -0.0222,  0.0160, -0.0118, -0.0083,\n",
      "        -0.0113,  0.0264, -0.0126,  0.0092,  0.0387,  0.0688,  0.0744,  0.0521,\n",
      "        -0.0882,  0.0569,  0.0859,  0.0502,  0.0468,  0.0860, -0.0543, -0.0726],\n",
      "       requires_grad=True) torch.Size([256])\n",
      "out.weight Parameter containing:\n",
      "tensor([[-0.0057, -0.0349,  0.0059,  ...,  0.0469,  0.0231, -0.0468],\n",
      "        [-0.0069,  0.0318, -0.0243,  ...,  0.0271,  0.0223, -0.0163],\n",
      "        [-0.0261, -0.0429, -0.0565,  ..., -0.0523, -0.0278, -0.0554],\n",
      "        ...,\n",
      "        [-0.0483,  0.0616, -0.0208,  ..., -0.0440,  0.0592,  0.0251],\n",
      "        [-0.0310, -0.0232,  0.0534,  ..., -0.0162,  0.0048, -0.0312],\n",
      "        [-0.0140, -0.0513,  0.0232,  ...,  0.0218, -0.0272, -0.0127]],\n",
      "       requires_grad=True) torch.Size([10, 256])\n",
      "out.bias Parameter containing:\n",
      "tensor([ 0.0166, -0.0115, -0.0058, -0.0604,  0.0225,  0.0525, -0.0320, -0.0321,\n",
      "        -0.0083, -0.0474], requires_grad=True) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# 遍历打印出 每个隐层的权重参数\n",
    "for name, parameter in net.named_parameters():\n",
    "    print(name, parameter,parameter.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用TensorDataset和DataLoader来简化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "# shuffle 就是打乱样本的顺序\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一般在训练模型时加上model.train()，这样会正常使用Batch Normalization和 Dropout\n",
    "- 测试的时候一般选择model.eval()，这样就不会使用Batch Normalization和 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(steps, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for step in range(steps):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        print('当前step:'+str(step), '验证集损失：'+str(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "def get_model():\n",
    "    model = Mnist_NN()\n",
    "    return model, optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        # 计算梯度\n",
    "        loss.backward()\n",
    "        # 根据梯度，更新权重\n",
    "        opt.step()\n",
    "        # 梯度清零\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三行搞定！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前step:0 验证集损失：0.1777562872931361\n",
      "当前step:1 验证集损失：0.14038255805820227\n",
      "当前step:2 验证集损失：0.1179858381435275\n",
      "当前step:3 验证集损失：0.1107424683753401\n",
      "当前step:4 验证集损失：0.10240991352647542\n",
      "当前step:5 验证集损失：0.09774479250572622\n",
      "当前step:6 验证集损失：0.09132455458845944\n",
      "当前step:7 验证集损失：0.09679921030793338\n",
      "当前step:8 验证集损失：0.08993808611398563\n",
      "当前step:9 验证集损失：0.08578289449326694\n",
      "当前step:10 验证集损失：0.09019483960885555\n",
      "当前step:11 验证集损失：0.08934408285841346\n",
      "当前step:12 验证集损失：0.08703555625323206\n",
      "当前step:13 验证集损失：0.0837827185086906\n",
      "当前step:14 验证集损失：0.08226691671377048\n",
      "当前step:15 验证集损失：0.08270146215418353\n",
      "当前step:16 验证集损失：0.08551770655401052\n",
      "当前step:17 验证集损失：0.08007037173761054\n",
      "当前step:18 验证集损失：0.07825443392845337\n",
      "当前step:19 验证集损失：0.08237732252993155\n",
      "当前step:20 验证集损失：0.07874089258648455\n",
      "当前step:21 验证集损失：0.08321938387306872\n",
      "当前step:22 验证集损失：0.08219939473322593\n",
      "当前step:23 验证集损失：0.08465245862061856\n",
      "当前step:24 验证集损失：0.0811437179874163\n",
      "当前step:25 验证集损失：0.07909511350432877\n",
      "当前step:26 验证集损失：0.0788751167197479\n",
      "当前step:27 验证集损失：0.07901946911145932\n",
      "当前step:28 验证集损失：0.07872889636938926\n",
      "当前step:29 验证集损失：0.0790572081850376\n",
      "当前step:30 验证集损失：0.08028549355440191\n",
      "当前step:31 验证集损失：0.0782628852231428\n",
      "当前step:32 验证集损失：0.0832707766374806\n",
      "当前step:33 验证集损失：0.08061861487745774\n",
      "当前step:34 验证集损失：0.0764548489785986\n",
      "当前step:35 验证集损失：0.07734377767529804\n",
      "当前step:36 验证集损失：0.07906249831307213\n",
      "当前step:37 验证集损失：0.07878289061214891\n",
      "当前step:38 验证集损失：0.07666742122746655\n",
      "当前step:39 验证集损失：0.07895392513258849\n",
      "当前step:40 验证集损失：0.08013912729675648\n",
      "当前step:41 验证集损失：0.07965616887956857\n",
      "当前step:42 验证集损失：0.07887082325962838\n",
      "当前step:43 验证集损失：0.08199827582184226\n",
      "当前step:44 验证集损失：0.08285375353726558\n",
      "当前step:45 验证集损失：0.08035772859868594\n",
      "当前step:46 验证集损失：0.08338608144515892\n",
      "当前step:47 验证集损失：0.0791220844354364\n",
      "当前step:48 验证集损失：0.0818248830327473\n",
      "当前step:49 验证集损失：0.07982436371049843\n",
      "当前step:50 验证集损失：0.08028131086364156\n",
      "当前step:51 验证集损失：0.08151552119934931\n",
      "当前step:52 验证集损失：0.07909247369393706\n",
      "当前step:53 验证集损失：0.07899567865035496\n",
      "当前step:54 验证集损失：0.0792677271003602\n",
      "当前step:55 验证集损失：0.07962960138909984\n",
      "当前step:56 验证集损失：0.08284689528235467\n",
      "当前step:57 验证集损失：0.07913987844820367\n",
      "当前step:58 验证集损失：0.07628310088247527\n",
      "当前step:59 验证集损失：0.08062557720417389\n",
      "当前step:60 验证集损失：0.08117417777148075\n",
      "当前step:61 验证集损失：0.08104190718697792\n",
      "当前step:62 验证集损失：0.08367284673673567\n",
      "当前step:63 验证集损失：0.08222651053890004\n",
      "当前step:64 验证集损失：0.08492360958271893\n",
      "当前step:65 验证集损失：0.08393378209045622\n",
      "当前step:66 验证集损失：0.07918654796381597\n",
      "当前step:67 验证集损失：0.08280705948420801\n",
      "当前step:68 验证集损失：0.08356791776810424\n",
      "当前step:69 验证集损失：0.08114261759745423\n",
      "当前step:70 验证集损失：0.08331993154078372\n",
      "当前step:71 验证集损失：0.08242305054243479\n",
      "当前step:72 验证集损失：0.08003229465561454\n",
      "当前step:73 验证集损失：0.08023025881183567\n",
      "当前step:74 验证集损失：0.08158916635077912\n",
      "当前step:75 验证集损失：0.08173911616396508\n",
      "当前step:76 验证集损失：0.0830736579769291\n",
      "当前step:77 验证集损失：0.08493236855674768\n",
      "当前step:78 验证集损失：0.09166055267078337\n",
      "当前step:79 验证集损失：0.0851533376430627\n",
      "当前step:80 验证集损失：0.08226081315295306\n",
      "当前step:81 验证集损失：0.0939468349439092\n",
      "当前step:82 验证集损失：0.08530883838083828\n",
      "当前step:83 验证集损失：0.08728977430116501\n",
      "当前step:84 验证集损失：0.08762569363914663\n",
      "当前step:85 验证集损失：0.0890317443813663\n",
      "当前step:86 验证集损失：0.08686970221174416\n",
      "当前step:87 验证集损失：0.08326867130145256\n",
      "当前step:88 验证集损失：0.08769855537793482\n",
      "当前step:89 验证集损失：0.08409761285634013\n",
      "当前step:90 验证集损失：0.0842176510968362\n",
      "当前step:91 验证集损失：0.08905635831609834\n",
      "当前step:92 验证集损失：0.08343756780446274\n",
      "当前step:93 验证集损失：0.08673203555926448\n",
      "当前step:94 验证集损失：0.0863895869371714\n",
      "当前step:95 验证集损失：0.08863903209397103\n",
      "当前step:96 验证集损失：0.09106719825812616\n",
      "当前step:97 验证集损失：0.08568818018380553\n",
      "当前step:98 验证集损失：0.09122793289180844\n",
      "当前step:99 验证集损失：0.08609709537455347\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(100, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 将优化器由SGD修改成 Adam\n",
    "2. 更改网络层数 和神经元个数 观察效果\n",
    "3. 计算当前的准确率是多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.84\n"
     ]
    }
   ],
   "source": [
    "# 正确率是要使用在验证集\n",
    "correct = 0\n",
    "total = 0\n",
    "for xb,yb in valid_dl:\n",
    "    outputs = model(xb)\n",
    "    _,predicted = torch.max(outputs.data,1)# 最大值和索引\n",
    "    total += yb.size(0)\n",
    "    correct += (predicted == yb).sum().item()\n",
    "\n",
    "print(100 * correct / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
